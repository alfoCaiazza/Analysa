{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f97d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acaia/Analysa/Analysa/.analysa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bc5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, aggr='mean'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.SAGEConv(in_channels, 2 * out_channels, aggr=aggr) # Eventually change layer type\n",
    "        self.batch1 = pyg_nn.BatchNorm(2 * out_channels)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = pyg_nn.SAGEConv(2 * out_channels, out_channels,  aggr=aggr) # Eventually change layer type\n",
    "        self.batch2 = pyg_nn.BatchNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index): # Modify to adapt to the dataset complexity\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.batch2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear = nn.Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # By default, it computes the inner product of the node embeddings\n",
    "        adj = torch.matmul(z[edge_index[0]], z[edge_index[1]].t())\n",
    "        return adj[edge_index[0], edge_index[1]]\n",
    "    \n",
    "# Defining traing and evaluation functions\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_data.edge_index.to(device))\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    # Encode the node features to get the embeddings\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_data.edge_index.to(device))\n",
    "    \n",
    "    # Compute the reconstruction loss\n",
    "    return model.test(z, pos_edge_index.to(device), neg_edge_index.to(device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb870c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "LATENT_DIM = 32\n",
    "data_path = os.path.join('..', 'data', 'graph_data.pt')\n",
    "dataset = torch.load(data_path, weights_only=False)\n",
    "data = dataset['data']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Instantiate the customized encoder in GAE model\n",
    "transform = RandomLinkSplit(is_undirected=True, split_labels=True,add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "model = pyg_nn.GAE(Encoder(data.num_features, LATENT_DIM)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "x = train_data.x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbf51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 38.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation: AUC: 0.7458, AP: 0.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(1, 1001)):\n",
    "    loss = train(epoch)\n",
    "    # AUC tells how well the model is able to distinguish real nodes from fake ones\n",
    "    # AP - Average Precision is the complementary metric of AUC \n",
    "    auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "\n",
    "\n",
    "print('Final Evaluation: AUC: {:.4f}, AP: {:.4f}'.format(auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18150031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4250\n",
      "Number of edges: 20102\n",
      "Embedding sample: tensor([[-0.0148,  0.3190, -0.2321,  ...,  0.2931, -0.2364, -0.0416],\n",
      "        [ 0.4805, -0.4786, -0.2518,  ...,  0.6031, -0.8688, -0.7159],\n",
      "        [-0.0649, -3.2233, -7.3970,  ...,  1.2354, -7.0063,  7.7511],\n",
      "        ...,\n",
      "        [-6.3847,  4.2103,  2.0474,  ...,  6.0607,  4.0489, -1.4764],\n",
      "        [-0.1624, -3.6282, -8.8758,  ...,  1.5324, -7.7481,  9.3953],\n",
      "        [-6.4098,  4.2184,  2.0403,  ...,  6.0689,  4.0344, -1.5072]],\n",
      "       device='cuda:0', grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_data.edge_index.to(device))\n",
    "emb_sample = z[0]\n",
    "print(f'Number of nodes: {z.shape[0]}')\n",
    "print(f'Number of edges: {train_data.edge_index.shape[1]}')\n",
    "print(f'Embedding sample: {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccca24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list = dataset['idx2user']\n",
    "embeddings = z\n",
    "embeddings_np = embeddings.cpu().detach().numpy()\n",
    "\n",
    "df = pd.DataFrame(embeddings_np)\n",
    "df.insert(loc=0, column='id', value=range(len(embeddings_np)))\n",
    "df.insert(loc=1, column='user_id', value= df['id'].map(mapping_list))\n",
    "\n",
    "df.to_csv('user_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
