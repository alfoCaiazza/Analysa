{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f97d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import RandomLinkSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60bc5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.GCNConv(in_channels, 2 * out_channels, cached=True) # Eventually change layer type\n",
    "        self.conv2 = pyg_nn.GCNConv(2 * out_channels, out_channels, cached=True) # Eventually change layer type\n",
    "\n",
    "    def forward(self, x, edge_index): # Modify to adapt to the dataset complexity\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear = nn.Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # By default, it computes the inner product of the node embeddings\n",
    "        adj = torch.matmul(z[edge_index[0]], z[edge_index[1]].t())\n",
    "        return adj[edge_index[0], edge_index[1]]\n",
    "    \n",
    "# Defining traing and evaluation functions\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_data.edge_index.to(device))\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    # Encode the node features to get the embeddings\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_data.edge_index.to(device))\n",
    "    \n",
    "    # Compute the reconstruction loss\n",
    "    return model.test(z, pos_edge_index.to(device), neg_edge_index.to(device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb870c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "import os\n",
    "LATENT_DIM = 32\n",
    "data_path = os.path.join('..', 'data', 'graph_data.pt')\n",
    "dataset = torch.load(data_path, weights_only=False)\n",
    "data = dataset['data']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Instantiate the customized encoder in GAE model\n",
    "transform = RandomLinkSplit(is_undirected=True, split_labels=True,add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "model = pyg_nn.GAE(Encoder(data.num_features, LATENT_DIM)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "x = train_data.x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcbf51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.7734, AP: 0.7989\n",
      "Epoch: 020, AUC: 0.7638, AP: 0.7920\n",
      "Epoch: 030, AUC: 0.7721, AP: 0.7980\n",
      "Epoch: 040, AUC: 0.7863, AP: 0.8083\n",
      "Epoch: 050, AUC: 0.7932, AP: 0.8135\n",
      "Epoch: 060, AUC: 0.8025, AP: 0.8205\n",
      "Epoch: 070, AUC: 0.8093, AP: 0.8253\n",
      "Epoch: 080, AUC: 0.8157, AP: 0.8293\n",
      "Epoch: 090, AUC: 0.8219, AP: 0.8321\n",
      "Epoch: 100, AUC: 0.8260, AP: 0.8332\n",
      "Epoch: 110, AUC: 0.8249, AP: 0.8317\n",
      "Epoch: 120, AUC: 0.8197, AP: 0.8283\n",
      "Epoch: 130, AUC: 0.8143, AP: 0.8249\n",
      "Epoch: 140, AUC: 0.8087, AP: 0.8213\n",
      "Epoch: 150, AUC: 0.8024, AP: 0.8170\n",
      "Epoch: 160, AUC: 0.8023, AP: 0.8171\n",
      "Epoch: 170, AUC: 0.8005, AP: 0.8159\n",
      "Epoch: 180, AUC: 0.8028, AP: 0.8176\n",
      "Epoch: 190, AUC: 0.8002, AP: 0.8158\n",
      "Epoch: 200, AUC: 0.8008, AP: 0.8163\n",
      "Epoch: 210, AUC: 0.8011, AP: 0.8164\n",
      "Epoch: 220, AUC: 0.8013, AP: 0.8166\n",
      "Epoch: 230, AUC: 0.7978, AP: 0.8142\n",
      "Epoch: 240, AUC: 0.7994, AP: 0.8154\n",
      "Epoch: 250, AUC: 0.8020, AP: 0.8172\n",
      "Epoch: 260, AUC: 0.7997, AP: 0.8156\n",
      "Epoch: 270, AUC: 0.7985, AP: 0.8148\n",
      "Epoch: 280, AUC: 0.7969, AP: 0.8137\n",
      "Epoch: 290, AUC: 0.7986, AP: 0.8148\n",
      "Epoch: 300, AUC: 0.8013, AP: 0.8167\n",
      "Epoch: 310, AUC: 0.8007, AP: 0.8163\n",
      "Epoch: 320, AUC: 0.8004, AP: 0.8160\n",
      "Epoch: 330, AUC: 0.8029, AP: 0.8178\n",
      "Epoch: 340, AUC: 0.8004, AP: 0.8160\n",
      "Epoch: 350, AUC: 0.7990, AP: 0.8149\n",
      "Epoch: 360, AUC: 0.7991, AP: 0.8150\n",
      "Epoch: 370, AUC: 0.8006, AP: 0.8160\n",
      "Epoch: 380, AUC: 0.8003, AP: 0.8158\n",
      "Epoch: 390, AUC: 0.8008, AP: 0.8162\n",
      "Epoch: 400, AUC: 0.8018, AP: 0.8169\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, 401):\n",
    "    loss = train(epoch)\n",
    "    auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18150031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4877\n",
      "Number of edges: 20618\n",
      "Embedding sample: tensor([[ 1.4475],\n",
      "        [ 1.1396],\n",
      "        [ 0.6645],\n",
      "        ...,\n",
      "        [-0.7973],\n",
      "        [-0.7973],\n",
      "        [-0.7973]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_data.edge_index.to(device))\n",
    "emb_sample = z[0]\n",
    "print(f'Number of nodes: {z.shape[0]}')\n",
    "print(f'Number of edges: {train_data.edge_index.shape[1]}')\n",
    "print(f'Embedding sample: {z}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
