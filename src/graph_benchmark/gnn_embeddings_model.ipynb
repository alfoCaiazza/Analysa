{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f97d908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acaia/Analysa/Analysa/.analysa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60bc5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, aggr='mean'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.SAGEConv(in_channels, 2 * out_channels, aggr=aggr) # Eventually change layer type\n",
    "        self.batch1 = pyg_nn.BatchNorm(2 * out_channels)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = pyg_nn.SAGEConv(2 * out_channels, out_channels,  aggr=aggr) # Eventually change layer type\n",
    "        self.batch2 = pyg_nn.BatchNorm(out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index): # Modify to adapt to the dataset complexity\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.batch2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear = nn.Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # By default, it computes the inner product of the node embeddings\n",
    "        adj = torch.matmul(z[edge_index[0]], z[edge_index[1]].t())\n",
    "        return adj[edge_index[0], edge_index[1]]\n",
    "    \n",
    "# Defining traing and evaluation functions\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_data.edge_index.to(device))\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    # Encode the node features to get the embeddings\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_data.edge_index.to(device))\n",
    "    \n",
    "    # Compute the reconstruction loss\n",
    "    return model.test(z, pos_edge_index.to(device), neg_edge_index.to(device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb870c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "import os\n",
    "LATENT_DIM = 32\n",
    "data_path = os.path.join('..', 'data', 'graph_data.pt')\n",
    "dataset = torch.load(data_path, weights_only=False)\n",
    "data = dataset['data']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Instantiate the customized encoder in GAE model\n",
    "transform = RandomLinkSplit(is_undirected=True, split_labels=True,add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "model = pyg_nn.GAE(Encoder(data.num_features, LATENT_DIM)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "x = train_data.x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbf51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, AUC: 0.6211, AP: 0.6234\n",
      "Epoch: 020, AUC: 0.7824, AP: 0.7604\n",
      "Epoch: 030, AUC: 0.8189, AP: 0.7987\n",
      "Epoch: 040, AUC: 0.8277, AP: 0.8043\n",
      "Epoch: 050, AUC: 0.8319, AP: 0.8069\n",
      "Epoch: 060, AUC: 0.8364, AP: 0.8092\n",
      "Epoch: 070, AUC: 0.8350, AP: 0.8075\n",
      "Epoch: 080, AUC: 0.8328, AP: 0.8067\n",
      "Epoch: 090, AUC: 0.8309, AP: 0.8062\n",
      "Epoch: 100, AUC: 0.8326, AP: 0.8081\n",
      "Epoch: 110, AUC: 0.8262, AP: 0.8082\n",
      "Epoch: 120, AUC: 0.8154, AP: 0.8007\n",
      "Epoch: 130, AUC: 0.7937, AP: 0.7775\n",
      "Epoch: 140, AUC: 0.8235, AP: 0.8086\n",
      "Epoch: 150, AUC: 0.8170, AP: 0.8005\n",
      "Epoch: 160, AUC: 0.8206, AP: 0.8060\n",
      "Epoch: 170, AUC: 0.8240, AP: 0.8098\n",
      "Epoch: 180, AUC: 0.8167, AP: 0.8021\n",
      "Epoch: 190, AUC: 0.8066, AP: 0.7942\n",
      "Epoch: 200, AUC: 0.8177, AP: 0.8009\n",
      "Epoch: 210, AUC: 0.7948, AP: 0.7770\n",
      "Epoch: 220, AUC: 0.8104, AP: 0.7974\n",
      "Epoch: 230, AUC: 0.7841, AP: 0.7638\n",
      "Epoch: 240, AUC: 0.7608, AP: 0.7277\n",
      "Epoch: 250, AUC: 0.7774, AP: 0.7519\n",
      "Epoch: 260, AUC: 0.8091, AP: 0.7955\n",
      "Epoch: 270, AUC: 0.7950, AP: 0.7780\n",
      "Epoch: 280, AUC: 0.7337, AP: 0.6987\n",
      "Epoch: 290, AUC: 0.7528, AP: 0.7247\n",
      "Epoch: 300, AUC: 0.7370, AP: 0.6923\n",
      "Epoch: 310, AUC: 0.7758, AP: 0.7452\n",
      "Epoch: 320, AUC: 0.7601, AP: 0.7195\n",
      "Epoch: 330, AUC: 0.7992, AP: 0.7781\n",
      "Epoch: 340, AUC: 0.7896, AP: 0.7604\n",
      "Epoch: 350, AUC: 0.8040, AP: 0.7824\n",
      "Epoch: 360, AUC: 0.7352, AP: 0.6867\n",
      "Epoch: 370, AUC: 0.7416, AP: 0.7111\n",
      "Epoch: 380, AUC: 0.7615, AP: 0.7370\n",
      "Epoch: 390, AUC: 0.7613, AP: 0.7328\n",
      "Epoch: 400, AUC: 0.7754, AP: 0.7556\n",
      "Epoch: 410, AUC: 0.8020, AP: 0.7826\n",
      "Epoch: 420, AUC: 0.7612, AP: 0.7245\n",
      "Epoch: 430, AUC: 0.7261, AP: 0.6927\n",
      "Epoch: 440, AUC: 0.7067, AP: 0.6457\n",
      "Epoch: 450, AUC: 0.7330, AP: 0.6879\n",
      "Epoch: 460, AUC: 0.7514, AP: 0.7216\n",
      "Epoch: 470, AUC: 0.7540, AP: 0.7252\n",
      "Epoch: 480, AUC: 0.7796, AP: 0.7609\n",
      "Epoch: 490, AUC: 0.7714, AP: 0.7495\n",
      "Epoch: 500, AUC: 0.7703, AP: 0.7490\n",
      "Epoch: 510, AUC: 0.7622, AP: 0.7410\n",
      "Epoch: 520, AUC: 0.7981, AP: 0.7860\n",
      "Epoch: 530, AUC: 0.7663, AP: 0.7383\n",
      "Epoch: 540, AUC: 0.7268, AP: 0.6877\n",
      "Epoch: 550, AUC: 0.7046, AP: 0.6683\n",
      "Epoch: 560, AUC: 0.7619, AP: 0.7331\n",
      "Epoch: 570, AUC: 0.8037, AP: 0.7861\n",
      "Epoch: 580, AUC: 0.7664, AP: 0.7448\n",
      "Epoch: 590, AUC: 0.8007, AP: 0.7819\n",
      "Epoch: 600, AUC: 0.7785, AP: 0.7633\n",
      "Epoch: 610, AUC: 0.7603, AP: 0.7370\n",
      "Epoch: 620, AUC: 0.7794, AP: 0.7624\n",
      "Epoch: 630, AUC: 0.7654, AP: 0.7445\n",
      "Epoch: 640, AUC: 0.7929, AP: 0.7758\n",
      "Epoch: 650, AUC: 0.7288, AP: 0.6985\n",
      "Epoch: 660, AUC: 0.7883, AP: 0.7713\n",
      "Epoch: 670, AUC: 0.7419, AP: 0.7121\n",
      "Epoch: 680, AUC: 0.7736, AP: 0.7542\n",
      "Epoch: 690, AUC: 0.7655, AP: 0.7429\n",
      "Epoch: 700, AUC: 0.7597, AP: 0.7311\n",
      "Epoch: 710, AUC: 0.7890, AP: 0.7683\n",
      "Epoch: 720, AUC: 0.7853, AP: 0.7638\n",
      "Epoch: 730, AUC: 0.7770, AP: 0.7559\n",
      "Epoch: 740, AUC: 0.7801, AP: 0.7664\n",
      "Epoch: 750, AUC: 0.7472, AP: 0.7137\n",
      "Epoch: 760, AUC: 0.7513, AP: 0.7293\n",
      "Epoch: 770, AUC: 0.7793, AP: 0.7622\n",
      "Epoch: 780, AUC: 0.7856, AP: 0.7775\n",
      "Epoch: 790, AUC: 0.7406, AP: 0.7062\n",
      "Epoch: 800, AUC: 0.7294, AP: 0.6857\n",
      "Epoch: 810, AUC: 0.7771, AP: 0.7587\n",
      "Epoch: 820, AUC: 0.7463, AP: 0.7115\n",
      "Epoch: 830, AUC: 0.7367, AP: 0.6998\n",
      "Epoch: 840, AUC: 0.7258, AP: 0.6807\n",
      "Epoch: 850, AUC: 0.7485, AP: 0.7262\n",
      "Epoch: 860, AUC: 0.7504, AP: 0.7225\n",
      "Epoch: 870, AUC: 0.7893, AP: 0.7691\n",
      "Epoch: 880, AUC: 0.7812, AP: 0.7617\n",
      "Epoch: 890, AUC: 0.8119, AP: 0.7984\n",
      "Epoch: 900, AUC: 0.8049, AP: 0.7950\n",
      "Epoch: 910, AUC: 0.7630, AP: 0.7307\n",
      "Epoch: 920, AUC: 0.6603, AP: 0.6055\n",
      "Epoch: 930, AUC: 0.7494, AP: 0.7031\n",
      "Epoch: 940, AUC: 0.6970, AP: 0.6518\n",
      "Epoch: 950, AUC: 0.7319, AP: 0.6927\n",
      "Epoch: 960, AUC: 0.6989, AP: 0.6558\n",
      "Epoch: 970, AUC: 0.7426, AP: 0.7103\n",
      "Epoch: 980, AUC: 0.7922, AP: 0.7720\n",
      "Epoch: 990, AUC: 0.7808, AP: 0.7590\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, 1000):\n",
    "    loss = train(epoch)\n",
    "    # AUC tells how well the model is able to distinguish real nodes from fake ones\n",
    "    # AP - Average Precision is the complementary metric of AUC \n",
    "    auc, ap = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18150031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4681\n",
      "Number of edges: 20236\n",
      "Embedding sample: tensor([[ 0.2127,  0.1965,  0.2142,  ...,  0.2129,  0.1164, -0.7988],\n",
      "        [-0.0487, -0.1120,  0.6771,  ...,  0.1587, -0.3308, -1.1364],\n",
      "        [-0.0772, -7.5162,  0.5632,  ..., -0.1415, -5.4869, -5.2316],\n",
      "        ...,\n",
      "        [-6.0341,  0.1309, -2.1863,  ..., -2.2882, -0.6434,  0.1236],\n",
      "        [-6.0327,  0.1309, -2.1866,  ..., -2.2895, -0.6445,  0.1243],\n",
      "        [-6.0341,  0.1309, -2.1863,  ..., -2.2882, -0.6434,  0.1236]],\n",
      "       device='cuda:0', grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, train_data.edge_index.to(device))\n",
    "emb_sample = z[0]\n",
    "print(f'Number of nodes: {z.shape[0]}')\n",
    "print(f'Number of edges: {train_data.edge_index.shape[1]}')\n",
    "print(f'Embedding sample: {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccca24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list = dataset['idx2user']\n",
    "embeddings = z\n",
    "embeddings_np = embeddings.cpu().detach().numpy()\n",
    "\n",
    "df = pd.DataFrame(embeddings_np)\n",
    "df.insert(loc=0, column='id', value=range(len(embeddings_np)))\n",
    "df.insert(loc=1, column='user_id', value= df['id'].map(mapping_list))\n",
    "\n",
    "df.to_csv('user_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
