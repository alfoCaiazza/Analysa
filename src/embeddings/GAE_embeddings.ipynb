{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f97d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, aggr='lstm'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = pyg_nn.SAGEConv(in_channels, 2 * out_channels, aggr=aggr) # Eventually change layer type\n",
    "        self.batch1 = pyg_nn.BatchNorm(2 * out_channels)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.conv2 = pyg_nn.SAGEConv(2 * out_channels, out_channels,  aggr=aggr) # Eventually change layer type\n",
    "        self.batch2 = pyg_nn.BatchNorm(out_channels)\n",
    "        self.drop2 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x, edge_index): # Modify to adapt to the dataset complexity\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.batch1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.batch2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Defining early stopping callback\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_auc = 0\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "# Defining traing and evaluation functions\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_data.edge_index.to(device))\n",
    "    loss = model.recon_loss(z, train_data.pos_edge_label_index.to(device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    # Encode the node features to get the embeddings\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_data.edge_index.to(device))\n",
    "    \n",
    "    # Compute the reconstruction loss\n",
    "    return model.test(z, pos_edge_index.to(device), neg_edge_index.to(device))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb870c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "LATENT_DIM = 32\n",
    "data_path = os.path.join('..', 'data', 'graph_data.pt')\n",
    "dataset = torch.load(data_path, weights_only=False)\n",
    "data = dataset['data']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Instantiate the customized encoder in GAE model\n",
    "transform = RandomLinkSplit(is_undirected=True, split_labels=True,add_negative_train_samples=True)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "model = pyg_nn.GAE(Encoder(data.num_features, LATENT_DIM)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "x = train_data.x.to(device)\n",
    "\n",
    "# Instantiating early stopper\n",
    "early_stopper = EarlyStopping(patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcbf51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1000 [00:00<00:43, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] | Val AUC: 0.6417 | Val AP: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 26/1000 [00:01<00:34, 28.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] | Val AUC: 0.7659 | Val AP: 0.8089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 34/1000 [00:01<00:32, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] | Val AUC: 0.7876 | Val AP: 0.8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 46/1000 [00:01<00:29, 32.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40] | Val AUC: 0.8269 | Val AP: 0.8420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 54/1000 [00:01<00:32, 28.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50] | Val AUC: 0.8278 | Val AP: 0.8423\n",
      "Early stopping triggered.\n",
      "Final Test Evaluation: AUC: 0.8187, AP: 0.8279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(1, 1001)):\n",
    "    loss = train(epoch)\n",
    "    # AUC tells how well the model is able to distinguish real nodes from fake ones\n",
    "    # AP - Average Precision is the complementary metric of AUC \n",
    "    auc_val, ap_val = test(val_data.pos_edge_label_index, val_data.neg_edge_label_index)\n",
    "    early_stopper(auc_val)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"[Epoch {epoch}] | Val AUC: {auc_val:.4f} | Val AP: {ap_val:.4f}\")\n",
    "    \n",
    "    if early_stopper.early_stop:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "    \n",
    "auc_test, ap_test = test(test_data.pos_edge_label_index, test_data.neg_edge_label_index)\n",
    "print('Final Test Evaluation: AUC: {:.4f}, AP: {:.4f}'.format(auc_test, ap_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18150031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4250\n",
      "Number of edges: 28266\n",
      "Embedding sample: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [2.4177, 2.3349, 2.3633,  ..., 2.2226, 2.3124, 2.1132],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [2.5407, 2.6702, 2.6679,  ..., 2.2492, 2.6820, 2.4381],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "z = model.encode(x, data.edge_index.to(device))\n",
    "emb_sample = z[0]\n",
    "print(f'Number of nodes: {z.shape[0]}')\n",
    "print(f'Number of edges: {data.edge_index.shape[1]}')\n",
    "print(f'Embedding sample: {z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccca24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_list = dataset['idx2user']\n",
    "embeddings = z\n",
    "embeddings_np = embeddings.cpu().detach().numpy()\n",
    "\n",
    "df = pd.DataFrame(embeddings_np)\n",
    "df.insert(loc=0, column='id', value=range(len(embeddings_np)))\n",
    "df.insert(loc=1, column='user_id', value= df['id'].map(mapping_list))\n",
    "\n",
    "df.to_csv('user_embeddings.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
