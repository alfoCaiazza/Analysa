{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544f9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acaia/Analysa/Analysa/.analysa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297477a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>type</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coteup</td>\n",
       "      <td>post</td>\n",
       "      <td>talk structural issues 3rd parties face us pol...</td>\n",
       "      <td>talk structur issu 3rd parti face us polit sys...</td>\n",
       "      <td>talk structural issue 3rd party face u politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_alpinisto</td>\n",
       "      <td>post</td>\n",
       "      <td>discovered sitting president committed exact c...</td>\n",
       "      <td>discov sit presid commit exact crime nixon for...</td>\n",
       "      <td>discover sit president commit exact crime nixo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PsychLegalMind</td>\n",
       "      <td>post</td>\n",
       "      <td>trump announced new weapons ukraine monday thr...</td>\n",
       "      <td>trump announc new weapon ukrain monday threate...</td>\n",
       "      <td>trump announce new weapon ukraine monday threa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaytee319</td>\n",
       "      <td>post</td>\n",
       "      <td>illinois considering new bill hb 3458 let some...</td>\n",
       "      <td>illinoi consid new bill hb 3458 let someon avo...</td>\n",
       "      <td>illinois consider new bill hb 3458 let someone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the_original_Retro</td>\n",
       "      <td>post</td>\n",
       "      <td>recent days maga outspoken influencers rushing...</td>\n",
       "      <td>recent day maga outspoken influenc rush call t...</td>\n",
       "      <td>recent day maga outspoken influencers rush cal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  type  \\\n",
       "0              Coteup  post   \n",
       "1          _alpinisto  post   \n",
       "2      PsychLegalMind  post   \n",
       "3           jaytee319  post   \n",
       "4  the_original_Retro  post   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  talk structural issues 3rd parties face us pol...   \n",
       "1  discovered sitting president committed exact c...   \n",
       "2  trump announced new weapons ukraine monday thr...   \n",
       "3  illinois considering new bill hb 3458 let some...   \n",
       "4  recent days maga outspoken influencers rushing...   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  talk structur issu 3rd parti face us polit sys...   \n",
       "1  discov sit presid commit exact crime nixon for...   \n",
       "2  trump announc new weapon ukrain monday threate...   \n",
       "3  illinoi consid new bill hb 3458 let someon avo...   \n",
       "4  recent day maga outspoken influenc rush call t...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  talk structural issue 3rd party face u politic...  \n",
       "1  discover sit president commit exact crime nixo...  \n",
       "2  trump announce new weapon ukraine monday threa...  \n",
       "3  illinois consider new bill hb 3458 let someone...  \n",
       "4  recent day maga outspoken influencers rush cal...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../src/nlp/cleaned_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8bd24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 16:26:07.703439: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-10 16:26:07.723140: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754835967.742631   13660 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754835967.748880   13660 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754835967.766327   13660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754835967.766347   13660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754835967.766349   13660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754835967.766351   13660 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-10 16:26:07.772004: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = f\"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "MAX_LENGHT = model.config.max_position_embeddings\n",
    "\n",
    "# Setting cuda environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e678ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split a list of token into smaller chunks so that each chunk fits within the model's maximum token length.\n",
    "# Special tokens (<s> and </s>), so max_length - 2\n",
    "def chunk_tokens(token_ids, max_length=(MAX_LENGHT - 4)):\n",
    "    for i in range(0, len(token_ids), max_length):\n",
    "        yield token_ids[i:i+max_length]\n",
    "\n",
    "# Function to run sentiment analysis on a long text by:\n",
    "# 1. Splitting it into token chunks\n",
    "# 2. Running the model on each chunk separately\n",
    "# 3. Averaging the sentiment scores across all chunks\n",
    "def sentiment_for_long_text(text, device):\n",
    "    # Convert text into token IDs without adding special tokens yet\n",
    "    token_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    sentiments = []\n",
    "\n",
    "    for token_chunk in chunk_tokens(token_ids):\n",
    "        # Manually add special tokens at the start and end\n",
    "        input_ids = [tokenizer.cls_token_id] + token_chunk + [tokenizer.sep_token_id]\n",
    "        # Create an attention mask (1 for each token)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Convert input IDs and mask into PyTorch tensors and move them to the target device (CPU/GPU)\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor([input_ids], device=device),\n",
    "            \"attention_mask\": torch.tensor([attention_mask], device=device)\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        sentiments.append(outputs.logits.softmax(dim=-1))\n",
    "\n",
    "    # Stack all sentiment probability tensors and compute the mean across chunks\n",
    "    return torch.mean(torch.stack(sentiments), dim=0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff349068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores(text, device):\n",
    "    if len(text) >= (MAX_LENGHT - 2):\n",
    "        scores_tensor = sentiment_for_long_text(text, device)\n",
    "    else:\n",
    "        encoded_text = tokenizer(text, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_text)\n",
    "        \n",
    "        scores_tensor = output.logits[0].softmax(dim=-1)\n",
    "\n",
    "    scores = scores_tensor.detach().cpu().numpy()\n",
    "\n",
    "    labels = ['negative','neutral','positive']\n",
    "\n",
    "    scores_dict = {\n",
    "        'neg_percentage' : scores[0],\n",
    "        'neu_percentage' : scores[1],\n",
    "        'pos_percentage' : scores[2],\n",
    "        'predicted_sentiment' : labels[scores.argmax()]\n",
    "    }\n",
    "\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64426adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/279018 [00:00<33:07:38,  2.34it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (209 > 128). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 279018/279018 [47:01<00:00, 98.90it/s] \n"
     ]
    }
   ],
   "source": [
    "INFORMAL_MODEL_NAME = \"bertweet\"\n",
    "results = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = row['clean_text']\n",
    "        author = row['author']\n",
    "\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            results.append({\n",
    "            'author': author,\n",
    "            'model': INFORMAL_MODEL_NAME,\n",
    "            'neg_percentage': None,\n",
    "            'neu_percentage': None,\n",
    "            'pos_percentage': None,\n",
    "            'predicted_sentiment': None\n",
    "            })\n",
    "        else: \n",
    "            result = polarity_scores(text, device)\n",
    "            results.append({\n",
    "                'author' : author,\n",
    "                'model' : INFORMAL_MODEL_NAME,\n",
    "                **result\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR at row {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d869b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "original_dataframe = pd.read_csv('../../src/nlp/sentiment_scores.csv')\n",
    "\n",
    "df_concat = pd.concat([original_dataframe, df], ignore_index=True)\n",
    "df_concat.to_csv('sentiment_scores.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
