{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "544f9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "297477a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---AI---</td>\n",
       "      <td>agreed deleted sorry took wrong way huge step ...</td>\n",
       "      <td>agre delet sorri took wrong way huge step ai a...</td>\n",
       "      <td>agree deleted sorry take wrong way huge step a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---Spartacus---</td>\n",
       "      <td>end goal produce stupid population reliably vo...</td>\n",
       "      <td>end goal produc stupid popul reliabl vote equa...</td>\n",
       "      <td>end goal produce stupid population reliably vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---____--__-_-_-___-</td>\n",
       "      <td>gross understatement lol</td>\n",
       "      <td>gross understat lol</td>\n",
       "      <td>gross understatement lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---chewie--</td>\n",
       "      <td>oh man let know months first lot afraid ever k...</td>\n",
       "      <td>oh man let know month first lot afraid ever ki...</td>\n",
       "      <td>oh man let know month first lot afraid ever ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>---why-so-serious---</td>\n",
       "      <td>lock bathroom you re good</td>\n",
       "      <td>lock bathroom you re good</td>\n",
       "      <td>lock bathroom you re good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                         clean_text  \\\n",
       "0              ---AI---  agreed deleted sorry took wrong way huge step ...   \n",
       "1       ---Spartacus---  end goal produce stupid population reliably vo...   \n",
       "2  ---____--__-_-_-___-                           gross understatement lol   \n",
       "3           ---chewie--  oh man let know months first lot afraid ever k...   \n",
       "4  ---why-so-serious---                          lock bathroom you re good   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0  agre delet sorri took wrong way huge step ai a...   \n",
       "1  end goal produc stupid popul reliabl vote equa...   \n",
       "2                                gross understat lol   \n",
       "3  oh man let know month first lot afraid ever ki...   \n",
       "4                          lock bathroom you re good   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  agree deleted sorry take wrong way huge step a...  \n",
       "1  end goal produce stupid population reliably vo...  \n",
       "2                           gross understatement lol  \n",
       "3  oh man let know month first lot afraid ever ki...  \n",
       "4                          lock bathroom you re good  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../src/nlp/cleaned_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc8bd24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Setting cuda environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e678ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split a list of token into smaller chunks so that each chunk fits within the model's maximum token length.\n",
    "# Special tokens (<s> and </s>), so max_length=510.\n",
    "def chunk_tokens(token_ids, max_length=510):\n",
    "    for i in range(0, len(token_ids), max_length):\n",
    "        yield token_ids[i:i+max_length]\n",
    "\n",
    "# Function to run sentiment analysis on a long text by:\n",
    "# 1. Splitting it into token chunks\n",
    "# 2. Running the model on each chunk separately\n",
    "# 3. Averaging the sentiment scores across all chunks\n",
    "def sentiment_for_long_text(text, device):\n",
    "    # Convert text into token IDs without adding special tokens yet\n",
    "    token_ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "    sentiments = []\n",
    "\n",
    "    for token_chunk in chunk_tokens(token_ids):\n",
    "        # Manually add special tokens at the start and end\n",
    "        input_ids = [tokenizer.cls_token_id] + token_chunk + [tokenizer.sep_token_id]\n",
    "        # Create an attention mask (1 for each token)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Convert input IDs and mask into PyTorch tensors and move them to the target device (CPU/GPU)\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.tensor([input_ids], device=device),\n",
    "            \"attention_mask\": torch.tensor([attention_mask], device=device)\n",
    "        }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        sentiments.append(outputs.logits.softmax(dim=-1))\n",
    "\n",
    "    # Stack all sentiment probability tensors and compute the mean across chunks\n",
    "    return torch.mean(torch.stack(sentiments), dim=0).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff349068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores(text, device):\n",
    "    if len(text) >= 514:\n",
    "        scores_tensor = sentiment_for_long_text(text, device)\n",
    "    else:\n",
    "        encoded_text = tokenizer(text, return_tensors='pt').to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_text)\n",
    "        \n",
    "        scores_tensor = output.logits[0].softmax(dim=-1)\n",
    "\n",
    "    scores = scores_tensor.detach().cpu().numpy()\n",
    "\n",
    "    labels = ['negative','neutral','positive']\n",
    "\n",
    "    scores_dict = {\n",
    "        'neg_percentage' : scores[0],\n",
    "        'neu_percentage' : scores[1],\n",
    "        'pos_percentage' : scores[2],\n",
    "        'predicted_sentiment' : labels[scores.argmax()]\n",
    "    }\n",
    "\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64426adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 345/1000 [00:12<00:14, 43.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore alla riga 339: object of type 'float' has no len()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 537/1000 [00:18<00:10, 44.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore alla riga 531: object of type 'float' has no len()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 674/1000 [00:22<00:12, 26.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore alla riga 674: object of type 'float' has no len()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 758/1000 [00:23<00:01, 148.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errore alla riga 751: object of type 'float' has no len()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:30<00:00, 32.44it/s]\n"
     ]
    }
   ],
   "source": [
    "INFORMAL_MODEL_NAME = \"roberta\"\n",
    "results = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        text = row['clean_text']\n",
    "        author = row['author']\n",
    "\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            results.append({\n",
    "            'author': author,\n",
    "            'model': INFORMAL_MODEL_NAME,\n",
    "            'neg_percentage': None,\n",
    "            'neu_percentage': None,\n",
    "            'pos_percentage': None,\n",
    "            'predicted_sentiment': None\n",
    "            })\n",
    "        else: \n",
    "            result = polarity_scores(text, device)\n",
    "            results.append({\n",
    "                'author' : author,\n",
    "                'model' : INFORMAL_MODEL_NAME,\n",
    "                **result\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR at row {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "original_dataframe = pd.read_csv('../../src/nlp/sentiment_scores.csv')\n",
    "\n",
    "df_concat = pd.concat([original_dataframe, df], ignore_index=True)\n",
    "df_concat.to_csv('sentiment_scores.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
