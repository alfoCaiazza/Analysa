{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8acb4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from cdlib import evaluation, algorithms\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d96886ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional metrics\n",
    "def compute_internal_density(G, nodes):\n",
    "    subG = G.subgraph(nodes)\n",
    "    n = len(subG.nodes())\n",
    "    m = len(subG.edges())\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    return (2 * m) / (n * (n - 1))\n",
    "\n",
    "def compute_edges_cut(G, nodes):\n",
    "    sub_nodes = set(nodes)\n",
    "    edges_inside, edges_cut = 0, 0\n",
    "    for u in nodes:\n",
    "        for v in G.neighbors(u):\n",
    "            if v in sub_nodes:\n",
    "                edges_inside += 1\n",
    "            else:\n",
    "                edges_cut += 1\n",
    "    edges_inside = edges_inside // 2 \n",
    "    return edges_inside, edges_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34411056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 37 communities with Infomap\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "edges_path = os.path.join('..', '..', 'src', 'data', 'edges.csv')\n",
    "edges_df = pd.read_csv(edges_path)\n",
    "\n",
    "save_dir = os.path.join('..', '..', 'src', 'graph_dir', 'infomap_dir')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "graph_dir = os.path.join('..','..', 'src', 'data', 'graph_data.pt')\n",
    "data = torch.load(graph_dir, weights_only=False)\n",
    "graph = data['data']\n",
    "mapping = data['idx2user']\n",
    "\n",
    "# Extracting nodes position\n",
    "G_nx = to_networkx(graph, to_undirected=True)\n",
    "\n",
    "# Community detection with Infomap\n",
    "communities = algorithms.infomap(G_nx)\n",
    "print(f\"Detected {len(communities.communities)} communities with Infomap\")\n",
    "\n",
    "# Global metrics\n",
    "modularity_score = evaluation.newman_girvan_modularity(G_nx, communities).score\n",
    "conductances = evaluation.conductance(G_nx, communities, summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e7e1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for k, (cluster, cond_score) in enumerate(zip(communities.communities, conductances)):\n",
    "    num_users = len(cluster)\n",
    "    density = compute_internal_density(G_nx, cluster)\n",
    "    edges_in, edges_cut = compute_edges_cut(G_nx, cluster)\n",
    "\n",
    "    # Modularity gain (cdlib fornisce score complessivo ma possiamo stimare locale)\n",
    "    modularity_gain = edges_in / (edges_in + edges_cut + 1e-9)\n",
    "\n",
    "    records.append({\n",
    "        \"id\": k,\n",
    "        \"users\": [mapping[node_id] for node_id in cluster],\n",
    "        \"num_users\": num_users,\n",
    "        \"density\": density,\n",
    "        \"conductance\": cond_score,\n",
    "        \"modularity_gain\": modularity_gain,\n",
    "        \"edges_inside\": edges_in,\n",
    "        \"edges_cut\": edges_cut\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features = df[[\"density\", \"num_users\", \"modularity_gain\", \"conductance\"]].copy()\n",
    "features[\"inv_conductance\"] = 1 - features[\"conductance\"]\n",
    "features = features.drop(columns=\"conductance\")\n",
    "\n",
    "df[\"inv_conductance\"] = 1 - df[\"conductance\"]\n",
    "\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "# Automatic clustering based on score metric\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "df[\"cluster_score\"] = kmeans.transform(X).min(axis=1)\n",
    "df[\"category\"] = labels\n",
    "\n",
    "cat_map = {\n",
    "    0: \"Weak\",\n",
    "    1: \"Moderate\",\n",
    "    2: \"Strong\",\n",
    "    3: \"Very Strong\"\n",
    "}\n",
    "\n",
    "order = df.groupby(\"category\")[\"inv_conductance\"].mean().sort_values().index\n",
    "cat_map = {cat: name for cat, name in zip(order, [\"Weak\", \"Moderate\", \"Strong\", \"Very Strong\"])}\n",
    "\n",
    "df[\"category_name\"] = df[\"category\"].map(cat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6bc04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_name\n",
      "Moderate       25\n",
      "Strong          4\n",
      "Very Strong     1\n",
      "Weak            7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Save cluster info to JSON\n",
    "cluster_tree_base = {}\n",
    "for row in df.to_dict(\"records\"):\n",
    "    cluster_tree_base[str(row[\"id\"])] = {\n",
    "        \"users\": [str(u) for u in row[\"users\"]],\n",
    "        \"type\": row[\"category_name\"],\n",
    "        \"conductance\": float(row[\"conductance\"]),\n",
    "        \"internal_density\": float(row[\"density\"]),\n",
    "        \"edges_inside\": int(row[\"edges_inside\"]),\n",
    "        \"edges_cut\": int(row[\"edges_cut\"]),\n",
    "        \"modularity_gain\": float(row[\"modularity_gain\"]),\n",
    "        \"num_users\": int(row[\"num_users\"]),\n",
    "        \"cluster_score\": float(row[\"cluster_score\"])\n",
    "    }\n",
    "\n",
    "with open(os.path.join(save_dir, 'cluster_tree_base.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(cluster_tree_base, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(df.groupby(\"category_name\").size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
