{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8acb4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sknetwork as skn\n",
    "from sknetwork.clustering import Louvain, get_modularity\n",
    "from sknetwork.linalg import normalize\n",
    "from sknetwork.utils import get_membership\n",
    "from sknetwork.visualization import visualize_graph\n",
    "import networkx as nx  \n",
    "import torch\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cdlib import evaluation, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d96886ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional metrics\n",
    "def compute_internal_density(G, nodes):\n",
    "    subG = G.subgraph(nodes)\n",
    "    n = len(subG.nodes())\n",
    "    m = len(subG.edges())\n",
    "    if n <= 1:\n",
    "        return 0.0\n",
    "    return (2 * m) / (n * (n - 1))\n",
    "\n",
    "def compute_edges_cut(G, nodes):\n",
    "    sub_nodes = set(nodes)\n",
    "    edges_inside = 0\n",
    "    edges_cut = 0\n",
    "    for u in nodes:\n",
    "        for v in G.neighbors(u):\n",
    "            if v in sub_nodes:\n",
    "                edges_inside += 1\n",
    "            else:\n",
    "                edges_cut += 1\n",
    "    edges_inside = edges_inside // 2 \n",
    "    return edges_inside, edges_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34411056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 41 communities with Infomap\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "edges_path = os.path.join('..', '..', 'src', 'data', 'edges.csv')\n",
    "edges_df = pd.read_csv(edges_path)\n",
    "\n",
    "save_dir = os.path.join('..', '..', 'src', 'graph_dir', 'infomap_dir')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "graph_dir = os.path.join('..','..', 'src', 'data', 'graph_data.pt')\n",
    "data = torch.load(graph_dir, weights_only=False)\n",
    "graph = data['data']\n",
    "mapping = data['idx2user']\n",
    "\n",
    "# Extracting nodes position\n",
    "G_nx = to_networkx(graph, to_undirected=True)\n",
    "\n",
    "# Community detection with Infomap\n",
    "communities = algorithms.infomap(G_nx)\n",
    "print(f\"Detected {len(communities.communities)} communities with Infomap\")\n",
    "\n",
    "# Conductance\n",
    "conductances = evaluation.conductance(G_nx, communities, summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e7e1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "weights = {\n",
    "    \"density\": 0.2,\n",
    "    \"conductance\": 0.5,\n",
    "    \"size\": 0.2,\n",
    "    \"modularity\": 0.1\n",
    "}\n",
    "\n",
    "# Calcolo modularity totale\n",
    "modularity_score = evaluation.newman_girvan_modularity(G_nx, communities).score\n",
    "\n",
    "cluster_tree_base = {}\n",
    "very_strong_comm, strong_comm, moderate_comm, weak_comm, noisy_comm = 0, 0, 0, 0, 0\n",
    "\n",
    "# Raccolta valori per normalizzazione\n",
    "densities = []\n",
    "sizes = []\n",
    "mod_contribs = []\n",
    "for cluster in communities.communities:\n",
    "    num_users = len(cluster)\n",
    "    density = compute_internal_density(G_nx, cluster)\n",
    "    modularity_contrib = (density * num_users) / (modularity_score + 1e-9)\n",
    "    densities.append(density)\n",
    "    sizes.append(num_users)\n",
    "    mod_contribs.append(modularity_contrib)\n",
    "\n",
    "# Normalizzazione min-max\n",
    "densities = np.array(densities)\n",
    "sizes = np.array(sizes)\n",
    "mod_contribs = np.array(mod_contribs)\n",
    "\n",
    "dens_norm = (densities - densities.min()) / (densities.max() - densities.min() + 1e-9)\n",
    "sizes_norm = (sizes - sizes.min()) / (sizes.max() - sizes.min() + 1e-9)\n",
    "mod_norm = (mod_contribs - mod_contribs.min()) / (mod_contribs.max() - mod_contribs.min() + 1e-9)\n",
    "\n",
    "# Calcolo score e classificazione\n",
    "idx = 0\n",
    "for k, (cluster, cond_score) in enumerate(zip(communities.communities, conductances)):\n",
    "    num_users = len(cluster)\n",
    "    \n",
    "    density = compute_internal_density(G_nx, cluster)\n",
    "    edges_in, edges_cut = compute_edges_cut(G_nx, cluster)\n",
    "    modularity_contrib = (density * num_users) / (modularity_score + 1e-9)\n",
    "\n",
    "    # Prendi valori normalizzati\n",
    "    d = dens_norm[idx]\n",
    "    s = sizes_norm[idx]\n",
    "    m = mod_norm[idx]\n",
    "    c = 1 - cond_score  # più basso il conductance, meglio è\n",
    "\n",
    "    # Score combinato\n",
    "    cluster_score = (weights[\"density\"] * d +\n",
    "                        weights[\"conductance\"] * c +\n",
    "                        weights[\"size\"] * s +\n",
    "                        weights[\"modularity\"] * m)\n",
    "    \n",
    "    # Classificazione basata sullo score\n",
    "    if cluster_score > 0.75:\n",
    "        comm_type = \"Very Strong community\"\n",
    "        very_strong_comm += 1\n",
    "    elif cluster_score > 0.5:\n",
    "        comm_type = \"Strong community\"\n",
    "        strong_comm += 1\n",
    "    elif cluster_score > 0.25:\n",
    "        comm_type = \"Moderate community\"\n",
    "        moderate_comm += 1\n",
    "    else:\n",
    "        comm_type = \"Weak community\"\n",
    "        weak_comm += 1\n",
    "    \n",
    "    idx += 1  # incremento per valori normalizzati\n",
    "\n",
    "    users = [mapping[node_id] for node_id in cluster]\n",
    "    cluster_tree_base[str(k)] = {\n",
    "        \"users\": [str(u) for u in users],\n",
    "        \"type\": comm_type,\n",
    "        \"conductance\": float(cond_score),\n",
    "        \"internal_density\": float(density),\n",
    "        \"edges_inside\": edges_in,\n",
    "        \"edges_cut\": edges_cut,\n",
    "        \"modularity_contribution\": float(modularity_contrib),\n",
    "        \"num_users\": num_users,\n",
    "        \"community_score\": float(cluster_score)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6bc04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total communities: 41\n",
      "Very strong: 1\n",
      "Strong: 3\n",
      "Moderate: 7\n",
      "Weak: 30\n"
     ]
    }
   ],
   "source": [
    "# Save cluster info to JSON\n",
    "with open(os.path.join(save_dir, 'cluster_tree_base.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(cluster_tree_base, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\n",
    "    f\"Total communities: {len(communities.communities)}\\n\"\n",
    "    f\"Very strong: {very_strong_comm}\\n\"\n",
    "    f\"Strong: {strong_comm}\\n\"\n",
    "    f\"Moderate: {moderate_comm}\\n\"\n",
    "    f\"Weak: {weak_comm}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
