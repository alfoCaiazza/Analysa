{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acb4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acaia/Analysa/Analysa/.analysa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sknetwork as skn\n",
    "from sknetwork.clustering import Louvain, get_modularity\n",
    "from sknetwork.linalg import normalize\n",
    "from sknetwork.utils import get_membership\n",
    "from sknetwork.visualization import visualize_graph\n",
    "import networkx as nx  \n",
    "import torch\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix, to_networkx\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34411056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] [1111  922  760  480  320  217  160  140  103    6    4    3    2    2\n",
      "    2    2    2    2    2    2    2    2    2    2]\n"
     ]
    }
   ],
   "source": [
    "graph_dir = os.path.join('..','..', 'src', 'data', 'graph_data.pt')\n",
    "graph = torch.load(graph_dir, weights_only=False)\n",
    "data = graph['data']\n",
    "\n",
    "# Extracting adjacency matrix from graph torch file\n",
    "adjacency_matrix = to_scipy_sparse_matrix(data.edge_index)\n",
    "\n",
    "# Extracting nodes position\n",
    "G_nx = to_networkx(data, to_undirected=False)\n",
    "pos = nx.spring_layout(G_nx)\n",
    "positions = np.array([pos[i] for i in range(len(pos))])\n",
    "\n",
    "# Clusterizing the graph\n",
    "louvain = Louvain()\n",
    "labels = louvain.fit_predict(adjacency_matrix)\n",
    "labels_unique, counts = np.unique(labels, return_counts=True)\n",
    "print(labels_unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc17192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5210337850402389)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_modularity(adjacency_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6908c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_aggregate = louvain.aggregate_\n",
    "avg = normalize(get_membership(labels).T)\n",
    "position_aggregate = avg.dot(positions)\n",
    "labels_unique, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0b4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = np.unique(labels)\n",
    "\n",
    "cluster_nodes = {}\n",
    "for c in unique_clusters:\n",
    "    cluster = np.where(labels == c)[0]\n",
    "    if len(cluster) > 5: # If there are at least 10 users in the same cluser, preserves it\n",
    "        cluster_nodes[c] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6bc04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusterize community in cluster i\n",
    "mapping = graph['idx2user']\n",
    "exp_clusters = {}\n",
    "\n",
    "for k, cluster in cluster_nodes.items():\n",
    "    users = []\n",
    "    for node_id in cluster:\n",
    "        username = mapping.get(node_id)\n",
    "        users.append(username)\n",
    "\n",
    "    exp_clusters[k] = users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32dc6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_subgraph(cluster_id, users, edge_df, save_path):\n",
    "    print(f\"Processing cluster : {cluster_id} with {len(users)} users.\")\n",
    "    users = set(users)\n",
    "    edges = edge_df[edge_df['source'].isin(users) & edge_df['target'].isin(users)]\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        return\n",
    "\n",
    "    # Mapping id - users \n",
    "    user2idx = {uid: idx for idx, uid in enumerate(users)}\n",
    "    idx2user = {idx: uid for uid, idx in user2idx.items()}\n",
    "\n",
    "    # Creating edges and associated weights\n",
    "    edges_index = torch.tensor([\n",
    "        [user2idx[src] for src in edges['source']],\n",
    "        [user2idx[dst] for dst in edges['target']],\n",
    "    ], dtype=torch.long)\n",
    "\n",
    "    edges_weight = torch.tensor(edges['weight'].values, dtype=torch.float)\n",
    "\n",
    "    # Creating the subgraph aka the k-th cluster\n",
    "    x = torch.eye(len(user2idx))\n",
    "    data = Data(x=x, edge_index=edges_index, edge_weight=edges_weight)\n",
    "    torch.save({\n",
    "        'data': data,\n",
    "        'idx2user': idx2user,\n",
    "    }, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bb82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = os.path.join('..','..', 'src', 'data', 'graph_data.pt')\n",
    "\n",
    "def get_cluster_with_Louvain(subgraph_dir, threshold=0.55, min_users=5):\n",
    "    subgraph = torch.load(subgraph_dir, weights_only=False)\n",
    "    data = subgraph['data']\n",
    "\n",
    "    # Extracting adjacency matrix of the subgraph\n",
    "    adjacency_matrix = to_scipy_sparse_matrix(data.edge_index)\n",
    "\n",
    "    louvain = Louvain()\n",
    "    labels = louvain.fit_predict(adjacency_matrix)\n",
    "\n",
    "    modularity = get_modularity(adjacency_matrix, labels)\n",
    "\n",
    "    # This means that nodes are cohesive so there's no need to cluterize the subgraph more\n",
    "    if modularity < threshold:\n",
    "        return None\n",
    "    \n",
    "    print(f\"Modularity: {modularity}\")\n",
    "    \n",
    "    unique_clusters = np.unique(labels)\n",
    "    cluster_nodes = {}\n",
    "\n",
    "    for c in unique_clusters:\n",
    "        cluster = np.where(labels == c)[0]\n",
    "        if len(cluster) > min_users: # If there are at least 5 users in the same cluser, preserves it\n",
    "            cluster_nodes[c] = cluster\n",
    "\n",
    "    return cluster_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853691ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_clustering(edge_df, subgraph_path, base_cluster_id, base_output_dir, cluster_tree, depth=0, max_depth = 4):\n",
    "    # Stopping cluster creation at max_depth\n",
    "    if depth >= max_depth:\n",
    "        return\n",
    "    \n",
    "    subgraph = torch.load(subgraph_path, weights_only=False)\n",
    "    idx2user = subgraph['idx2user']\n",
    "    \n",
    "    cluster_tree[int(base_cluster_id)] = {\n",
    "        \"users\" : {str(idx2user[i]) for i in range(len(idx2user))},\n",
    "        \"children\" : {}\n",
    "    }\n",
    "    child_tree = cluster_tree[int(base_cluster_id)][\"children\"]\n",
    "    \n",
    "    new_clusters = get_cluster_with_Louvain(subgraph_path)\n",
    "    if new_clusters is None:\n",
    "        return\n",
    "\n",
    "    for sub_id, node_ids in new_clusters.items():\n",
    "        users = [idx2user[idx] for idx in node_ids]\n",
    "\n",
    "        cluster_id = f\"{base_cluster_id}_{sub_id}\"\n",
    "        save_path = os.path.join(base_output_dir, f\"subgraph_{cluster_id}.pt\")\n",
    "        \n",
    "        new_path = build_subgraph(cluster_id, users, edge_df, save_path=save_path)\n",
    "        if new_path:\n",
    "            recursive_clustering(\n",
    "            edge_df=edge_df,\n",
    "            subgraph_path=new_path,\n",
    "            base_cluster_id=cluster_id,\n",
    "            base_output_dir=base_output_dir,\n",
    "            cluster_tree = child_tree,\n",
    "            depth=depth + 1,\n",
    "            max_depth=max_depth\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb75316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to start the recursion\n",
    "def start_recursive_clustering(first_clusters, edges_path, base_output_dir, max_depth=4):\n",
    "    edges = pd.read_csv(edges_path)\n",
    "    cluster_tree = {}\n",
    "\n",
    "    for k, users in first_clusters.items():\n",
    "        save_path = os.path.join(base_output_dir, f'subgraph_{k}.pt')\n",
    "        new_cluster_dir = build_subgraph(k, users, edges, save_path)\n",
    "        if new_cluster_dir is not None:\n",
    "            recursive_clustering(\n",
    "                subgraph_path=new_cluster_dir,\n",
    "                base_cluster_id=k,\n",
    "                edge_df=edges,\n",
    "                base_output_dir=base_output_dir,\n",
    "                cluster_tree=cluster_tree,\n",
    "                depth=0,\n",
    "                max_depth=max_depth\n",
    "            )\n",
    "\n",
    "    return cluster_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea7fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cluster : 0 with 1111 users.\n",
      "Processing cluster : 1 with 922 users.\n",
      "Processing cluster : 2 with 760 users.\n",
      "Processing cluster : 3 with 480 users.\n",
      "Modularity: 0.6925070014516771\n",
      "Processing cluster : 3_0 with 47 users.\n",
      "Modularity: 0.6092825443786982\n",
      "Processing cluster : 3_0_0 with 10 users.\n",
      "Processing cluster : 3_0_1 with 7 users.\n",
      "Processing cluster : 3_0_2 with 6 users.\n",
      "Processing cluster : 3_0_3 with 6 users.\n",
      "Processing cluster : 3_0_4 with 6 users.\n",
      "Processing cluster : 3_1 with 41 users.\n",
      "Modularity: 0.571934558947546\n",
      "Processing cluster : 3_1_0 with 7 users.\n",
      "Processing cluster : 3_1_1 with 7 users.\n",
      "Processing cluster : 3_1_2 with 7 users.\n",
      "Processing cluster : 3_1_3 with 7 users.\n",
      "Processing cluster : 3_2 with 41 users.\n",
      "Modularity: 0.6195005945303211\n",
      "Processing cluster : 3_2_0 with 10 users.\n",
      "Processing cluster : 3_2_1 with 7 users.\n",
      "Processing cluster : 3_2_2 with 6 users.\n",
      "Processing cluster : 3_2_3 with 6 users.\n",
      "Processing cluster : 3_3 with 34 users.\n",
      "Modularity: 0.6472727272727272\n",
      "Processing cluster : 3_3_0 with 9 users.\n",
      "Processing cluster : 3_3_1 with 7 users.\n",
      "Processing cluster : 3_3_2 with 6 users.\n",
      "Processing cluster : 3_4 with 33 users.\n",
      "Modularity: 0.6198224852071006\n",
      "Processing cluster : 3_4_0 with 8 users.\n",
      "Processing cluster : 3_4_1 with 8 users.\n",
      "Processing cluster : 3_4_2 with 8 users.\n",
      "Processing cluster : 3_5 with 29 users.\n",
      "Modularity: 0.6105789254477302\n",
      "Processing cluster : 3_5_0 with 7 users.\n",
      "Processing cluster : 3_5_1 with 6 users.\n",
      "Processing cluster : 3_6 with 28 users.\n",
      "Modularity: 0.595679012345679\n",
      "Processing cluster : 3_6_0 with 9 users.\n",
      "Processing cluster : 3_7 with 28 users.\n",
      "Modularity: 0.6429980276134122\n",
      "Processing cluster : 3_7_0 with 7 users.\n",
      "Processing cluster : 3_8 with 26 users.\n",
      "Modularity: 0.5986394557823129\n",
      "Processing cluster : 3_8_0 with 7 users.\n",
      "Processing cluster : 3_9 with 25 users.\n",
      "Modularity: 0.5812016656751934\n",
      "Processing cluster : 3_9_0 with 6 users.\n",
      "Processing cluster : 3_10 with 25 users.\n",
      "Modularity: 0.5750000000000001\n",
      "Processing cluster : 3_10_0 with 7 users.\n",
      "Processing cluster : 3_11 with 24 users.\n",
      "Modularity: 0.5742630385487529\n",
      "Processing cluster : 3_11_0 with 8 users.\n",
      "Processing cluster : 3_12 with 24 users.\n",
      "Modularity: 0.6406135865595326\n",
      "Processing cluster : 3_12_0 with 7 users.\n",
      "Processing cluster : 3_13 with 23 users.\n",
      "Modularity: 0.6035502958579881\n",
      "Processing cluster : 3_13_0 with 6 users.\n",
      "Processing cluster : 3_13_1 with 6 users.\n",
      "Processing cluster : 3_14 with 20 users.\n",
      "Processing cluster : 3_15 with 16 users.\n",
      "Modularity: 0.551984877126654\n",
      "Processing cluster : 3_16 with 16 users.\n",
      "Processing cluster : 4 with 320 users.\n",
      "Modularity: 0.6966210613598673\n",
      "Processing cluster : 4_0 with 56 users.\n",
      "Processing cluster : 4_1 with 39 users.\n",
      "Modularity: 0.5746890472165198\n",
      "Processing cluster : 4_1_0 with 8 users.\n",
      "Processing cluster : 4_1_1 with 7 users.\n",
      "Processing cluster : 4_1_2 with 7 users.\n",
      "Processing cluster : 4_2 with 28 users.\n",
      "Modularity: 0.60932944606414\n",
      "Processing cluster : 4_2_0 with 7 users.\n",
      "Processing cluster : 4_2_1 with 6 users.\n",
      "Processing cluster : 4_3 with 28 users.\n",
      "Modularity: 0.5532525510204083\n",
      "Processing cluster : 4_3_0 with 8 users.\n",
      "Processing cluster : 4_3_1 with 7 users.\n",
      "Processing cluster : 4_3_2 with 7 users.\n",
      "Processing cluster : 4_3_3 with 6 users.\n",
      "Processing cluster : 4_4 with 25 users.\n",
      "Modularity: 0.6068052930056711\n",
      "Processing cluster : 4_4_0 with 7 users.\n",
      "Processing cluster : 4_4_1 with 6 users.\n",
      "Processing cluster : 4_4_2 with 6 users.\n",
      "Processing cluster : 4_5 with 23 users.\n",
      "Processing cluster : 4_6 with 22 users.\n",
      "Processing cluster : 4_7 with 19 users.\n",
      "Processing cluster : 4_8 with 19 users.\n",
      "Processing cluster : 4_9 with 17 users.\n",
      "Processing cluster : 4_10 with 12 users.\n",
      "Processing cluster : 4_11 with 10 users.\n",
      "Processing cluster : 4_12 with 7 users.\n",
      "Processing cluster : 5 with 217 users.\n",
      "Modularity: 0.6747323512393377\n",
      "Processing cluster : 5_0 with 28 users.\n",
      "Processing cluster : 5_1 with 24 users.\n",
      "Modularity: 0.5902646502835539\n",
      "Processing cluster : 5_2 with 21 users.\n",
      "Modularity: 0.5690357627885921\n",
      "Processing cluster : 5_2_0 with 7 users.\n",
      "Processing cluster : 5_3 with 21 users.\n",
      "Processing cluster : 5_4 with 19 users.\n",
      "Processing cluster : 5_5 with 17 users.\n",
      "Modularity: 0.5849609375\n",
      "Processing cluster : 5_5_0 with 6 users.\n",
      "Processing cluster : 5_6 with 16 users.\n",
      "Processing cluster : 5_7 with 16 users.\n",
      "Processing cluster : 5_8 with 14 users.\n",
      "Processing cluster : 5_9 with 12 users.\n",
      "Processing cluster : 5_10 with 11 users.\n",
      "Processing cluster : 5_11 with 9 users.\n",
      "Processing cluster : 5_12 with 9 users.\n",
      "Processing cluster : 6 with 160 users.\n",
      "Modularity: 0.7596409574468085\n",
      "Processing cluster : 6_0 with 26 users.\n",
      "Processing cluster : 6_1 with 24 users.\n",
      "Processing cluster : 6_2 with 19 users.\n",
      "Processing cluster : 6_3 with 15 users.\n",
      "Processing cluster : 6_4 with 13 users.\n",
      "Processing cluster : 6_5 with 13 users.\n",
      "Modularity: 0.565\n",
      "Processing cluster : 6_6 with 12 users.\n",
      "Processing cluster : 6_7 with 11 users.\n",
      "Processing cluster : 6_8 with 10 users.\n",
      "Processing cluster : 6_9 with 8 users.\n",
      "Processing cluster : 7 with 140 users.\n",
      "Modularity: 0.7627695690752672\n",
      "Processing cluster : 7_0 with 24 users.\n",
      "Processing cluster : 7_1 with 16 users.\n",
      "Processing cluster : 7_2 with 15 users.\n",
      "Processing cluster : 7_3 with 15 users.\n",
      "Processing cluster : 7_4 with 15 users.\n",
      "Processing cluster : 7_5 with 15 users.\n",
      "Processing cluster : 7_6 with 12 users.\n",
      "Processing cluster : 7_7 with 12 users.\n",
      "Processing cluster : 7_8 with 10 users.\n",
      "Processing cluster : 7_9 with 6 users.\n",
      "Processing cluster : 8 with 103 users.\n",
      "Modularity: 0.7713164729503214\n",
      "Processing cluster : 8_0 with 25 users.\n",
      "Processing cluster : 8_1 with 16 users.\n",
      "Processing cluster : 8_2 with 11 users.\n",
      "Processing cluster : 8_3 with 11 users.\n",
      "Processing cluster : 8_4 with 10 users.\n",
      "Processing cluster : 8_5 with 10 users.\n",
      "Processing cluster : 8_6 with 9 users.\n",
      "Processing cluster : 8_7 with 7 users.\n",
      "Processing cluster : 9 with 6 users.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def make_json_serializable(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): make_json_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, set):\n",
    "        return list(obj)\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_json_serializable(v) for v in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "edges_path = os.path.join('..', '..', 'src', 'data', 'edges.csv')\n",
    "save_dir = os.path.join('..', '..', 'src', 'graph_dir', 'subgraph_dir')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "cluster_tree = start_recursive_clustering(exp_clusters, edges_path, save_dir)\n",
    "json_safe_tree = make_json_serializable(cluster_tree)\n",
    "\n",
    "with open(os.path.join(save_dir, 'cluster_tree.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_safe_tree, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
