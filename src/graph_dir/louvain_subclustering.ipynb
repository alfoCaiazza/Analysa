{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acb4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acaia/Analysa/Analysa/.analysa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sknetwork as skn\n",
    "from sknetwork.clustering import Louvain, get_modularity\n",
    "from sknetwork.linalg import normalize\n",
    "from sknetwork.utils import get_membership\n",
    "from sknetwork.visualization import visualize_graph\n",
    "import networkx as nx  \n",
    "import torch\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix, to_networkx\n",
    "from torch_geometric.data import Data\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34411056",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = os.path.join('..','..', 'src', 'data', 'graph_data.pt')\n",
    "graph = torch.load(graph_dir, weights_only=False)\n",
    "data = graph['data']\n",
    "\n",
    "# Extracting adjacency matrix from graph torch file\n",
    "adjacency_matrix = to_scipy_sparse_matrix(data.edge_index)\n",
    "\n",
    "# Extracting nodes position\n",
    "G_nx = to_networkx(data, to_undirected=False)\n",
    "pos = nx.spring_layout(G_nx)\n",
    "positions = np.array([pos[i] for i in range(len(pos))])\n",
    "\n",
    "# Clusterizing the graph\n",
    "louvain = Louvain()\n",
    "labels = louvain.fit_predict(adjacency_matrix)\n",
    "labels_unique, counts = np.unique(labels, return_counts=True)\n",
    "print(labels_unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc17192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5210337850402389)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_modularity(adjacency_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6908c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_aggregate = louvain.aggregate_\n",
    "avg = normalize(get_membership(labels).T)\n",
    "position_aggregate = avg.dot(positions)\n",
    "labels_unique, counts = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c0b4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clusters = np.unique(labels)\n",
    "\n",
    "cluster_nodes = {}\n",
    "for c in unique_clusters:\n",
    "    cluster = np.where(labels == c)[0]\n",
    "    if len(cluster) > 5: # If there are at least 10 users in the same cluser, preserves it\n",
    "        cluster_nodes[c] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6bc04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusterize community in cluster i\n",
    "mapping = graph['idx2user']\n",
    "exp_clusters = {}\n",
    "\n",
    "for k, cluster in cluster_nodes.items():\n",
    "    users = []\n",
    "    for node_id in cluster:\n",
    "        username = mapping.get(node_id)\n",
    "        users.append(username)\n",
    "\n",
    "    exp_clusters[k] = users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32dc6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_subgraph(cluster_id, users, edge_df, save_path):\n",
    "    print(f\"Processing cluster : {cluster_id} with {len(users)} users.\")\n",
    "    users = set(users)\n",
    "    edges = edge_df[edge_df['source'].isin(users) & edge_df['target'].isin(users)]\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        return\n",
    "\n",
    "    # Mapping id - users \n",
    "    user2idx = {uid: idx for idx, uid in enumerate(users)}\n",
    "    idx2user = {idx: uid for uid, idx in user2idx.items()}\n",
    "\n",
    "    # Creating edges and associated weights\n",
    "    edges_index = torch.tensor([\n",
    "        [user2idx[src] for src in edges['source']],\n",
    "        [user2idx[dst] for dst in edges['target']],\n",
    "    ], dtype=torch.long)\n",
    "\n",
    "    edges_weight = torch.tensor(edges['weight'].values, dtype=torch.float)\n",
    "\n",
    "    # Creating the subgraph aka the k-th cluster\n",
    "    x = torch.eye(len(user2idx))\n",
    "    data = Data(x=x, edge_index=edges_index, edge_weight=edges_weight)\n",
    "    torch.save({\n",
    "        'data': data,\n",
    "        'idx2user': idx2user,\n",
    "    }, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = os.path.join('..','..', 'src', 'data', 'graph_data.pt')\n",
    "\n",
    "def get_cluster_with_Louvain(subgraph_dir, threshold=0.5, min_users=5):\n",
    "    subgraph = torch.load(subgraph_dir, weights_only=False)\n",
    "    data = subgraph['data']\n",
    "\n",
    "    # Extracting adjacency matrix of the subgraph\n",
    "    adjacency_matrix = to_scipy_sparse_matrix(data.edge_index)\n",
    "\n",
    "    louvain = Louvain()\n",
    "    labels = louvain.fit_predict(adjacency_matrix)\n",
    "\n",
    "    modularity = get_modularity(adjacency_matrix, labels)\n",
    "\n",
    "    # This means that nodes are cohesive so there's no need to cluterize the subgraph more\n",
    "    if modularity < threshold:\n",
    "        return None\n",
    "    \n",
    "    unique_clusters = np.unique(labels)\n",
    "    cluster_nodes = {}\n",
    "\n",
    "    for c in unique_clusters:\n",
    "        cluster = np.where(labels == c)[0]\n",
    "        if len(cluster) > min_users: # If there are at least 5 users in the same cluser, preserves it\n",
    "            cluster_nodes[c] = cluster\n",
    "\n",
    "    return cluster_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dea7fffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cluster : 0 with 1111 users.\n",
      "Processing cluster : 1 with 922 users.\n",
      "Processing cluster : 2 with 760 users.\n",
      "Processing cluster : 3 with 480 users.\n",
      "Processing cluster : 4 with 320 users.\n",
      "Processing cluster : 5 with 217 users.\n",
      "Processing cluster : 6 with 160 users.\n",
      "Processing cluster : 7 with 140 users.\n",
      "Processing cluster : 8 with 103 users.\n",
      "Processing cluster : 9 with 6 users.\n"
     ]
    }
   ],
   "source": [
    "edges_path = os.path.join('..', '..', 'src', 'data', 'edges.csv')\n",
    "edges = pd.read_csv(edges_path)\n",
    "\n",
    "save_dir = os.path.join('..', '..', 'src', 'graph_dir', 'subgraph_dir')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for k, users in exp_clusters.items():\n",
    "    save_path = os.path.join(save_dir, f'subgraph_{k}.pt')\n",
    "    build_subgraph(k, users, edges, save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".analysa (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
